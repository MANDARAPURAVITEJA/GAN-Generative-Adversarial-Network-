{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "342e26b8",
   "metadata": {},
   "source": [
    "# GAN ( Generative Adversarial Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7d82b",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6161490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "067f50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "#set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f752856",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538ac31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data',train=True, download=True, transform=ToTensor())\n",
    "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=4,\\\n",
    "                                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54de706a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = train_dataset.classes\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "779889f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frog': 5000,\n",
       " 'truck': 5000,\n",
       " 'deer': 5000,\n",
       " 'automobile': 5000,\n",
       " 'bird': 5000,\n",
       " 'horse': 5000,\n",
       " 'ship': 5000,\n",
       " 'cat': 5000,\n",
       " 'dog': 5000,\n",
       " 'airplane': 5000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_count = {}\n",
    "for _, index in train_dataset:\n",
    "    label = classes[index]\n",
    "    if label not in class_count:\n",
    "        class_count[label] = 0\n",
    "    class_count[label] += 1\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91960d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape: torch.Size([32, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for images, _ in dataloader:\n",
    "    print('images.shape:', images.shape)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b05aa",
   "metadata": {},
   "source": [
    "### Defining parameters to be used(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c03c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim =100\n",
    "lr = 0.0002\n",
    "beta1= 0.5\n",
    "beta2 = 0.9999\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b78a68",
   "metadata": {},
   "source": [
    "### Utility class for Building the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e39d160e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(latent_dim, 128*8*8),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (128,8,8)),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128, momentum=0.78),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64, momentum=0.78),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Tanh()       \n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26fedc0",
   "metadata": {},
   "source": [
    "### Utility class for Building the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab77e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    " \n",
    "        self.model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "        nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "        nn.BatchNorm2d(64, momentum=0.82),\n",
    "        nn.LeakyReLU(0.25),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(128, momentum=0.82),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.BatchNorm2d(256, momentum=0.8),\n",
    "        nn.LeakyReLU(0.25),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256 * 5 * 5, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    " \n",
    "    def forward(self, img):\n",
    "        validity = self.model(img)\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0230447",
   "metadata": {},
   "source": [
    "### Building the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ba64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and initialize Generator and Discriminator\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "#Loss function\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "#Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885b502",
   "metadata": {},
   "source": [
    "### Training the Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6ddbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]                        Batch 100/1563 Discriminator Loss: 0.6232 Generator Loss: 1.1653\n",
      "Epoch [1/10]                        Batch 200/1563 Discriminator Loss: 0.6602 Generator Loss: 0.9345\n",
      "Epoch [1/10]                        Batch 300/1563 Discriminator Loss: 0.7164 Generator Loss: 0.8172\n",
      "Epoch [1/10]                        Batch 400/1563 Discriminator Loss: 0.6349 Generator Loss: 0.8141\n",
      "Epoch [1/10]                        Batch 500/1563 Discriminator Loss: 0.7524 Generator Loss: 0.8042\n",
      "Epoch [1/10]                        Batch 600/1563 Discriminator Loss: 0.6341 Generator Loss: 0.9826\n",
      "Epoch [1/10]                        Batch 700/1563 Discriminator Loss: 0.6478 Generator Loss: 1.1971\n",
      "Epoch [1/10]                        Batch 800/1563 Discriminator Loss: 0.5715 Generator Loss: 0.9058\n",
      "Epoch [1/10]                        Batch 900/1563 Discriminator Loss: 0.5660 Generator Loss: 0.9817\n",
      "Epoch [1/10]                        Batch 1000/1563 Discriminator Loss: 0.5913 Generator Loss: 0.8895\n",
      "Epoch [1/10]                        Batch 1100/1563 Discriminator Loss: 0.6073 Generator Loss: 0.9792\n",
      "Epoch [1/10]                        Batch 1200/1563 Discriminator Loss: 0.7394 Generator Loss: 0.7283\n",
      "Epoch [1/10]                        Batch 1300/1563 Discriminator Loss: 0.5874 Generator Loss: 0.9058\n",
      "Epoch [1/10]                        Batch 1400/1563 Discriminator Loss: 0.6677 Generator Loss: 1.0839\n",
      "Epoch [1/10]                        Batch 1500/1563 Discriminator Loss: 0.6170 Generator Loss: 0.8487\n",
      "Epoch [2/10]                        Batch 100/1563 Discriminator Loss: 0.5566 Generator Loss: 1.0881\n",
      "Epoch [2/10]                        Batch 200/1563 Discriminator Loss: 0.4441 Generator Loss: 1.6596\n",
      "Epoch [2/10]                        Batch 300/1563 Discriminator Loss: 0.5759 Generator Loss: 1.3446\n",
      "Epoch [2/10]                        Batch 400/1563 Discriminator Loss: 0.6405 Generator Loss: 0.9404\n",
      "Epoch [2/10]                        Batch 500/1563 Discriminator Loss: 0.6274 Generator Loss: 0.8667\n",
      "Epoch [2/10]                        Batch 600/1563 Discriminator Loss: 0.5724 Generator Loss: 1.0527\n",
      "Epoch [2/10]                        Batch 700/1563 Discriminator Loss: 0.7156 Generator Loss: 0.7731\n",
      "Epoch [2/10]                        Batch 800/1563 Discriminator Loss: 0.5145 Generator Loss: 1.0517\n",
      "Epoch [2/10]                        Batch 900/1563 Discriminator Loss: 0.7289 Generator Loss: 0.8030\n",
      "Epoch [2/10]                        Batch 1000/1563 Discriminator Loss: 0.5931 Generator Loss: 0.9937\n",
      "Epoch [2/10]                        Batch 1100/1563 Discriminator Loss: 0.7425 Generator Loss: 0.9329\n",
      "Epoch [2/10]                        Batch 1200/1563 Discriminator Loss: 0.5641 Generator Loss: 0.9574\n",
      "Epoch [2/10]                        Batch 1300/1563 Discriminator Loss: 0.6893 Generator Loss: 0.9994\n",
      "Epoch [2/10]                        Batch 1400/1563 Discriminator Loss: 0.7373 Generator Loss: 0.8318\n",
      "Epoch [2/10]                        Batch 1500/1563 Discriminator Loss: 0.6128 Generator Loss: 1.1977\n",
      "Epoch [3/10]                        Batch 100/1563 Discriminator Loss: 0.6356 Generator Loss: 0.8845\n",
      "Epoch [3/10]                        Batch 200/1563 Discriminator Loss: 0.6384 Generator Loss: 1.0559\n",
      "Epoch [3/10]                        Batch 300/1563 Discriminator Loss: 0.6358 Generator Loss: 0.8137\n",
      "Epoch [3/10]                        Batch 400/1563 Discriminator Loss: 0.5814 Generator Loss: 1.1971\n",
      "Epoch [3/10]                        Batch 500/1563 Discriminator Loss: 0.6556 Generator Loss: 0.8786\n",
      "Epoch [3/10]                        Batch 600/1563 Discriminator Loss: 0.6477 Generator Loss: 1.0574\n",
      "Epoch [3/10]                        Batch 700/1563 Discriminator Loss: 0.5988 Generator Loss: 0.9401\n",
      "Epoch [3/10]                        Batch 800/1563 Discriminator Loss: 0.6541 Generator Loss: 0.8979\n",
      "Epoch [3/10]                        Batch 900/1563 Discriminator Loss: 0.6337 Generator Loss: 0.9406\n",
      "Epoch [3/10]                        Batch 1000/1563 Discriminator Loss: 0.5826 Generator Loss: 0.5652\n",
      "Epoch [3/10]                        Batch 1100/1563 Discriminator Loss: 0.7140 Generator Loss: 0.8319\n",
      "Epoch [3/10]                        Batch 1200/1563 Discriminator Loss: 0.6009 Generator Loss: 0.9084\n",
      "Epoch [3/10]                        Batch 1300/1563 Discriminator Loss: 0.6203 Generator Loss: 0.8108\n",
      "Epoch [3/10]                        Batch 1400/1563 Discriminator Loss: 0.6506 Generator Loss: 0.9835\n",
      "Epoch [3/10]                        Batch 1500/1563 Discriminator Loss: 0.5524 Generator Loss: 1.4440\n",
      "Epoch [4/10]                        Batch 100/1563 Discriminator Loss: 0.5412 Generator Loss: 0.9338\n",
      "Epoch [4/10]                        Batch 200/1563 Discriminator Loss: 0.6238 Generator Loss: 0.8544\n",
      "Epoch [4/10]                        Batch 300/1563 Discriminator Loss: 0.7072 Generator Loss: 1.0456\n",
      "Epoch [4/10]                        Batch 400/1563 Discriminator Loss: 0.6753 Generator Loss: 0.7797\n",
      "Epoch [4/10]                        Batch 500/1563 Discriminator Loss: 0.7397 Generator Loss: 0.8611\n",
      "Epoch [4/10]                        Batch 600/1563 Discriminator Loss: 0.7336 Generator Loss: 1.3158\n",
      "Epoch [4/10]                        Batch 700/1563 Discriminator Loss: 0.6836 Generator Loss: 1.0344\n",
      "Epoch [4/10]                        Batch 800/1563 Discriminator Loss: 0.7776 Generator Loss: 1.0072\n",
      "Epoch [4/10]                        Batch 900/1563 Discriminator Loss: 0.6729 Generator Loss: 1.1756\n",
      "Epoch [4/10]                        Batch 1000/1563 Discriminator Loss: 0.4632 Generator Loss: 1.3746\n",
      "Epoch [4/10]                        Batch 1100/1563 Discriminator Loss: 0.6937 Generator Loss: 0.7708\n",
      "Epoch [4/10]                        Batch 1200/1563 Discriminator Loss: 0.9619 Generator Loss: 0.6886\n",
      "Epoch [4/10]                        Batch 1300/1563 Discriminator Loss: 0.6288 Generator Loss: 0.9672\n",
      "Epoch [4/10]                        Batch 1400/1563 Discriminator Loss: 0.7094 Generator Loss: 1.1730\n",
      "Epoch [4/10]                        Batch 1500/1563 Discriminator Loss: 0.6654 Generator Loss: 0.7461\n",
      "Epoch [5/10]                        Batch 100/1563 Discriminator Loss: 0.7136 Generator Loss: 0.7661\n",
      "Epoch [5/10]                        Batch 200/1563 Discriminator Loss: 0.6890 Generator Loss: 1.1710\n",
      "Epoch [5/10]                        Batch 300/1563 Discriminator Loss: 0.7216 Generator Loss: 0.7177\n",
      "Epoch [5/10]                        Batch 400/1563 Discriminator Loss: 0.6611 Generator Loss: 1.1281\n",
      "Epoch [5/10]                        Batch 500/1563 Discriminator Loss: 0.7074 Generator Loss: 0.9723\n",
      "Epoch [5/10]                        Batch 600/1563 Discriminator Loss: 0.6009 Generator Loss: 0.9940\n",
      "Epoch [5/10]                        Batch 700/1563 Discriminator Loss: 0.6145 Generator Loss: 0.9148\n",
      "Epoch [5/10]                        Batch 800/1563 Discriminator Loss: 0.7024 Generator Loss: 1.0429\n",
      "Epoch [5/10]                        Batch 900/1563 Discriminator Loss: 0.4535 Generator Loss: 1.4415\n",
      "Epoch [5/10]                        Batch 1000/1563 Discriminator Loss: 0.5426 Generator Loss: 1.0373\n",
      "Epoch [5/10]                        Batch 1100/1563 Discriminator Loss: 0.6481 Generator Loss: 0.9881\n",
      "Epoch [5/10]                        Batch 1200/1563 Discriminator Loss: 0.8063 Generator Loss: 0.7717\n",
      "Epoch [5/10]                        Batch 1300/1563 Discriminator Loss: 0.7092 Generator Loss: 0.7574\n",
      "Epoch [5/10]                        Batch 1400/1563 Discriminator Loss: 0.7087 Generator Loss: 0.6031\n",
      "Epoch [5/10]                        Batch 1500/1563 Discriminator Loss: 0.6209 Generator Loss: 1.0823\n",
      "Epoch [6/10]                        Batch 100/1563 Discriminator Loss: 0.5456 Generator Loss: 1.1742\n",
      "Epoch [6/10]                        Batch 200/1563 Discriminator Loss: 0.6543 Generator Loss: 1.2876\n",
      "Epoch [6/10]                        Batch 300/1563 Discriminator Loss: 0.7847 Generator Loss: 0.8141\n",
      "Epoch [6/10]                        Batch 400/1563 Discriminator Loss: 0.6698 Generator Loss: 0.9796\n",
      "Epoch [6/10]                        Batch 500/1563 Discriminator Loss: 0.6126 Generator Loss: 1.3844\n",
      "Epoch [6/10]                        Batch 600/1563 Discriminator Loss: 0.6390 Generator Loss: 0.7235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]                        Batch 700/1563 Discriminator Loss: 0.5434 Generator Loss: 0.7162\n",
      "Epoch [6/10]                        Batch 800/1563 Discriminator Loss: 0.7455 Generator Loss: 0.7814\n",
      "Epoch [6/10]                        Batch 900/1563 Discriminator Loss: 0.5010 Generator Loss: 1.1024\n",
      "Epoch [6/10]                        Batch 1000/1563 Discriminator Loss: 0.8211 Generator Loss: 0.7927\n",
      "Epoch [6/10]                        Batch 1100/1563 Discriminator Loss: 0.6854 Generator Loss: 1.2134\n",
      "Epoch [6/10]                        Batch 1200/1563 Discriminator Loss: 0.6860 Generator Loss: 0.9473\n",
      "Epoch [6/10]                        Batch 1300/1563 Discriminator Loss: 0.6295 Generator Loss: 1.0821\n",
      "Epoch [6/10]                        Batch 1400/1563 Discriminator Loss: 0.5734 Generator Loss: 1.1597\n",
      "Epoch [6/10]                        Batch 1500/1563 Discriminator Loss: 0.7155 Generator Loss: 1.0721\n",
      "Epoch [7/10]                        Batch 100/1563 Discriminator Loss: 0.5986 Generator Loss: 0.9824\n",
      "Epoch [7/10]                        Batch 200/1563 Discriminator Loss: 0.5921 Generator Loss: 0.6331\n",
      "Epoch [7/10]                        Batch 300/1563 Discriminator Loss: 0.5845 Generator Loss: 0.7003\n",
      "Epoch [7/10]                        Batch 400/1563 Discriminator Loss: 0.7755 Generator Loss: 0.9078\n",
      "Epoch [7/10]                        Batch 500/1563 Discriminator Loss: 0.6090 Generator Loss: 1.0716\n",
      "Epoch [7/10]                        Batch 600/1563 Discriminator Loss: 0.7255 Generator Loss: 0.8432\n",
      "Epoch [7/10]                        Batch 700/1563 Discriminator Loss: 0.8720 Generator Loss: 0.5387\n",
      "Epoch [7/10]                        Batch 800/1563 Discriminator Loss: 0.6487 Generator Loss: 1.1060\n",
      "Epoch [7/10]                        Batch 900/1563 Discriminator Loss: 0.6725 Generator Loss: 0.9052\n",
      "Epoch [7/10]                        Batch 1000/1563 Discriminator Loss: 0.5480 Generator Loss: 1.1290\n",
      "Epoch [7/10]                        Batch 1100/1563 Discriminator Loss: 0.7474 Generator Loss: 0.4681\n",
      "Epoch [7/10]                        Batch 1200/1563 Discriminator Loss: 0.4684 Generator Loss: 1.1045\n",
      "Epoch [7/10]                        Batch 1300/1563 Discriminator Loss: 0.7610 Generator Loss: 0.4861\n",
      "Epoch [7/10]                        Batch 1400/1563 Discriminator Loss: 0.6839 Generator Loss: 0.9372\n",
      "Epoch [7/10]                        Batch 1500/1563 Discriminator Loss: 0.6665 Generator Loss: 0.8707\n",
      "Epoch [8/10]                        Batch 100/1563 Discriminator Loss: 0.6077 Generator Loss: 0.9149\n",
      "Epoch [8/10]                        Batch 200/1563 Discriminator Loss: 0.5253 Generator Loss: 1.4161\n",
      "Epoch [8/10]                        Batch 300/1563 Discriminator Loss: 0.5559 Generator Loss: 1.0227\n",
      "Epoch [8/10]                        Batch 400/1563 Discriminator Loss: 0.5561 Generator Loss: 1.0454\n",
      "Epoch [8/10]                        Batch 500/1563 Discriminator Loss: 0.6472 Generator Loss: 0.9938\n",
      "Epoch [8/10]                        Batch 600/1563 Discriminator Loss: 0.7612 Generator Loss: 0.8218\n",
      "Epoch [8/10]                        Batch 700/1563 Discriminator Loss: 0.5702 Generator Loss: 1.1940\n",
      "Epoch [8/10]                        Batch 800/1563 Discriminator Loss: 0.7068 Generator Loss: 0.7844\n",
      "Epoch [8/10]                        Batch 900/1563 Discriminator Loss: 0.6486 Generator Loss: 1.0534\n",
      "Epoch [8/10]                        Batch 1000/1563 Discriminator Loss: 0.4809 Generator Loss: 1.3851\n",
      "Epoch [8/10]                        Batch 1100/1563 Discriminator Loss: 0.7204 Generator Loss: 0.8437\n",
      "Epoch [8/10]                        Batch 1200/1563 Discriminator Loss: 0.5863 Generator Loss: 0.8913\n",
      "Epoch [8/10]                        Batch 1300/1563 Discriminator Loss: 0.5791 Generator Loss: 1.1583\n",
      "Epoch [8/10]                        Batch 1400/1563 Discriminator Loss: 0.6255 Generator Loss: 0.7766\n",
      "Epoch [8/10]                        Batch 1500/1563 Discriminator Loss: 0.6711 Generator Loss: 0.8771\n",
      "Epoch [9/10]                        Batch 100/1563 Discriminator Loss: 0.6587 Generator Loss: 0.8743\n",
      "Epoch [9/10]                        Batch 200/1563 Discriminator Loss: 0.6798 Generator Loss: 0.8345\n",
      "Epoch [9/10]                        Batch 300/1563 Discriminator Loss: 0.5309 Generator Loss: 0.8478\n",
      "Epoch [9/10]                        Batch 400/1563 Discriminator Loss: 0.7316 Generator Loss: 0.9725\n",
      "Epoch [9/10]                        Batch 500/1563 Discriminator Loss: 0.6589 Generator Loss: 0.7930\n",
      "Epoch [9/10]                        Batch 600/1563 Discriminator Loss: 0.7697 Generator Loss: 0.9567\n",
      "Epoch [9/10]                        Batch 700/1563 Discriminator Loss: 0.8574 Generator Loss: 1.1145\n",
      "Epoch [9/10]                        Batch 800/1563 Discriminator Loss: 0.6577 Generator Loss: 0.7515\n",
      "Epoch [9/10]                        Batch 900/1563 Discriminator Loss: 0.6562 Generator Loss: 1.1394\n",
      "Epoch [9/10]                        Batch 1000/1563 Discriminator Loss: 0.5173 Generator Loss: 1.4612\n",
      "Epoch [9/10]                        Batch 1100/1563 Discriminator Loss: 0.7415 Generator Loss: 0.5650\n",
      "Epoch [9/10]                        Batch 1200/1563 Discriminator Loss: 0.7264 Generator Loss: 0.8356\n",
      "Epoch [9/10]                        Batch 1300/1563 Discriminator Loss: 0.7443 Generator Loss: 0.7664\n",
      "Epoch [9/10]                        Batch 1400/1563 Discriminator Loss: 0.6170 Generator Loss: 1.0317\n",
      "Epoch [9/10]                        Batch 1500/1563 Discriminator Loss: 0.5205 Generator Loss: 1.3508\n",
      "Epoch [10/10]                        Batch 100/1563 Discriminator Loss: 0.6884 Generator Loss: 1.0132\n",
      "Epoch [10/10]                        Batch 200/1563 Discriminator Loss: 0.6900 Generator Loss: 1.1308\n",
      "Epoch [10/10]                        Batch 300/1563 Discriminator Loss: 0.8698 Generator Loss: 1.0144\n",
      "Epoch [10/10]                        Batch 400/1563 Discriminator Loss: 0.5128 Generator Loss: 0.9380\n",
      "Epoch [10/10]                        Batch 500/1563 Discriminator Loss: 0.7050 Generator Loss: 0.6334\n",
      "Epoch [10/10]                        Batch 600/1563 Discriminator Loss: 0.6695 Generator Loss: 0.9014\n",
      "Epoch [10/10]                        Batch 700/1563 Discriminator Loss: 0.5508 Generator Loss: 0.9589\n",
      "Epoch [10/10]                        Batch 800/1563 Discriminator Loss: 0.7280 Generator Loss: 0.6642\n",
      "Epoch [10/10]                        Batch 900/1563 Discriminator Loss: 0.6485 Generator Loss: 1.0392\n",
      "Epoch [10/10]                        Batch 1000/1563 Discriminator Loss: 0.6975 Generator Loss: 1.0960\n",
      "Epoch [10/10]                        Batch 1100/1563 Discriminator Loss: 0.6755 Generator Loss: 1.3159\n",
      "Epoch [10/10]                        Batch 1200/1563 Discriminator Loss: 0.7675 Generator Loss: 0.7485\n",
      "Epoch [10/10]                        Batch 1300/1563 Discriminator Loss: 0.6808 Generator Loss: 0.9316\n",
      "Epoch [10/10]                        Batch 1400/1563 Discriminator Loss: 0.5249 Generator Loss: 1.2449\n",
      "Epoch [10/10]                        Batch 1500/1563 Discriminator Loss: 0.8576 Generator Loss: 0.8295\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        #Convert list to tensor\n",
    "        real_images = batch[0].to(device)\n",
    "        \n",
    "        #Adversarial ground truths\n",
    "        valid = torch.ones(real_images.size(0), 1, device=device)\n",
    "        fake = torch.zeros(real_images.size(0), 1, device=device)\n",
    "        \n",
    "        #Configure input\n",
    "        real_images = real_images.to(device)\n",
    "        \n",
    "         # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        #sample noise as generator input\n",
    "        z = torch.randn(real_images.size(0), latent_dim, device=device)\n",
    "        \n",
    "               # Generate a batch of images\n",
    "        fake_images = generator(z)\n",
    " \n",
    "        # Measure discriminator's ability\n",
    "        # to classify real and fake images\n",
    "        real_loss = adversarial_loss(discriminator\\\n",
    "                                     (real_images), valid)\n",
    "        fake_loss = adversarial_loss(discriminator\\\n",
    "                                     (fake_images.detach()), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    " \n",
    "        # Backward pass and optimize\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    " \n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    " \n",
    "        optimizer_G.zero_grad()\n",
    " \n",
    "        # Generate a batch of images\n",
    "        gen_images = generator(z)\n",
    " \n",
    "        # Adversarial loss\n",
    "        g_loss = adversarial_loss(discriminator(gen_images), valid)\n",
    " \n",
    "        # Backward pass and optimize\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    " \n",
    "        # ---------------------\n",
    "        #  Progress Monitoring\n",
    "        # ---------------------\n",
    " \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}]\\\n",
    "                        Batch {i+1}/{len(dataloader)} \"\n",
    "                f\"Discriminator Loss: {d_loss.item():.4f} \"\n",
    "                f\"Generator Loss: {g_loss.item():.4f}\"\n",
    "            )\n",
    " \n",
    "    # Save generated images for every epoch\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16, latent_dim, device=device)\n",
    "            generated = generator(z).detach().cpu()\n",
    "            grid = torchvision.utils.make_grid(generated,\\\n",
    "                                        nrow=4, normalize=True)\n",
    "            plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9373a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
